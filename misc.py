from typing import List, Tuple

import torch
import torch.nn.functional as F
import numpy as np
from skimage.draw import random_shapes
import os
import json

# Mask size set for training here - Jamie
def get_masks_for_training(
        mask_shapes: List[Tuple] =
        [(64, 32, 32), (128, 16, 16), (256, 8, 8), (512, 4, 4), (512, 4, 4), (4096,), (10,)],
        #[(64, 64, 64), (128, 32, 32), (256, 16, 16), (512, 8, 8), (512, 4, 4), (4096,), (365,)],
        #[(64, 128, 128), (128, 64, 64), (256, 32, 32), (512, 16, 16), (512, 8, 8), (4096,), (365,)],
        # Masks for 64x64, 128x128 and 256x256 respectively - Jamie 15/01/21 11:54
        # Updated for 10 Classes - Jamie 25/01/21 17:03
        device: str = 'cpu', add_batch_size: bool = False,
        p_random_mask: float = 0.3) -> List[torch.Tensor]:
    '''
    Method returns random masks similar to 3.2. of the paper
    :param mask_shapes: (List[Tuple]) Shapes of the features generated by the vgg16 model
    :param device: (str) Device to store tensor masks
    :param add_batch_size: (bool) If true a batch size is added to each mask
    :param p_random_mask: (float) Probability that a random mask is generated else no mask is utilized
    :return: (List[torch.Tensor]) Generated masks for each feature tensor
    '''
    # Select layer where no masking is used. Every output from the deeper layers get mapped out. Every higher layer gets
    # masked by a random shape
    selected_layer = np.random.choice(range(7))
    # Make masks
    masks = []
    random_mask = None
    random_mask_used = False
    for index, mask_shape in enumerate(reversed(mask_shapes)):
        # Full mask on case
        if index < selected_layer:
            if len(mask_shape) > 1:
                # Save mask to list
                masks.append(torch.zeros((1, mask_shape[1], mask_shape[2]), dtype=torch.float32, device=device))
            else:
                # Save mask to list
                masks.append(torch.zeros(mask_shape, dtype=torch.float32, device=device))
        # No mask case
        elif index == selected_layer:
            if len(mask_shape) > 1:
                # Save mask to list
                masks.append(torch.ones((1, mask_shape[1], mask_shape[2]), dtype=torch.float32, device=device))
            else:
                # Save mask to list
                masks.append(torch.ones(mask_shape, dtype=torch.float32, device=device))
        # Random mask cases
        elif index > selected_layer and random_mask is None:
            spatial_varying_masks = np.random.rand() < p_random_mask
            #intial code always assumes if length(mask_shape) not >2 then mask would be randomly generated, this would
            # only ever apply to the 1st FC layer but updated to check to make layer non-random if the spatial probability
            # doens't say too.
            if len(mask_shape) > 2:
                # Get random mask
                if spatial_varying_masks:
                    random_mask_used = True
                    random_mask = random_shapes(mask_shape[1:],
                                                min_shapes=1,
                                                max_shapes=4,
                                                min_size=min(8, mask_shape[1] // 2),
                                                allow_overlap=True)[0][:, :, 0]
                    # Random mask to torch tensor
                    random_mask = torch.tensor(random_mask, dtype=torch.float32, device=device)[None, :, :]
                    # Change range of mask to [0, 1]
                    random_mask = (random_mask == 255.0).float()
                else:
                    # Make no mask
                    # From paper "In our default training step, we randomly select a pyramid level, and feed to the
                    # generator only the features at that level, while masking out the features in all other levels"
                    random_mask = torch.zeros(mask_shape[1:], dtype=torch.float32, device=device)[None, :, :]
                # Save mask to list
                masks.append(random_mask)
            else:
                if spatial_varying_masks:
                    # Save mask to list
                    # Was initially skeptical here but I realise this is done like this for 1D layers as spatial mask can't
                    # be upsampled from here.
                    masks.append(torch.randint(low=0, high=2, size=mask_shape, dtype=torch.float32, device=device))
                else:
                    random_mask = torch.zeros(mask_shape, dtype=torch.float32, device=device)
                    masks.append(random_mask)

        else:
            # Save mask to list
            if random_mask_used:
                masks.append(F.upsample_nearest(random_mask[None, :, :, :], size=mask_shape[1:]).float().to(device)[0])
            else:
                # From paper "In our default training step, we randomly select a pyramid level, and feed to the
                # generator only the features at that level, while masking out the features in all other levels"
                masks.append(torch.zeros(mask_shape[1:], dtype=torch.float32, device=device)[None, :, :])
    # Add batch size dimension
    if add_batch_size:
        for index in range(len(masks)):
            masks[index] = masks[index].unsqueeze(dim=0)
    # Reverse order of masks to match the features of the vgg16 model
    masks.reverse()
    return masks

# I believe this function hardcodes the masks shapes, may be worth looking into making this dynamic - Jamie
def get_masks_for_validation(mask_shapes: List[Tuple] =
                            [(64, 32, 32), (128, 16, 16), (256, 8, 8), (512, 4, 4), (512, 4, 4), (4096,), (10,)],
                            # [(64, 64, 64), (128, 32, 32), (256, 16, 16), (512, 8, 8), (512, 4, 4), (4096,), (365,)],
                            # [(64, 128, 128), (128, 64, 64), (256, 32, 32), (512, 16, 16), (512, 8, 8), (4096,), (365,)],
                            # Masks for 64x64, 128x128 and 256x256 respectively - Jamie 15/01/21 11:54
                            # Updated for 10 Classes - Jamie 25/01/21 17:03
                            device: str = 'cpu', add_batch_size: bool = False) -> List[torch.Tensor]:
    return get_masks_for_inference(layer_index_to_choose=np.random.choice(range(len(mask_shapes))),
                                   mask_shapes=mask_shapes, device=device, add_batch_size=add_batch_size)

# I believe this function hardcodes the masks shapes, may be worth looking into making this dynamic - Jamie
def get_masks_for_inference(layer_index_to_choose: int, mask_shapes: List[Tuple] =
                            [(64, 32, 32), (128, 16, 16), (256, 8, 8), (512, 4, 4), (512, 4, 4), (4096,), (10,)],
                            # [(64, 64, 64), (128, 32, 32), (256, 16, 16), (512, 8, 8), (512, 4, 4), (4096,), (365,)],
                            # [(64, 128, 128), (128, 64, 64), (256, 32, 32), (512, 16, 16), (512, 8, 8), (4096,), (365,)],
                            # Masks for 64x64, 128x128 and 256x256 respectively - Jamie 15/01/21 11:54
                            # Updated for 10 Classes - Jamie 25/01/21 17:03
                            device: str = 'cpu', add_batch_size: bool = False) -> List[torch.Tensor]:
    # Init list for masks
    masks = []
    # Loop over all shapes
    for index, mask_shape in enumerate(reversed(mask_shapes)):
        if index == layer_index_to_choose:
            if len(mask_shape) > 1:
                # Save mask to list
                masks.append(torch.ones((1, mask_shape[1], mask_shape[2]), dtype=torch.float32, device=device))
            else:
                # Save mask to list
                masks.append(torch.ones(mask_shape, dtype=torch.float32, device=device))
        else:
            if len(mask_shape) > 1:
                # Save mask to list
                masks.append(torch.zeros((1, mask_shape[1], mask_shape[2]), dtype=torch.float32, device=device))
            else:
                # Save mask to list
                masks.append(torch.zeros(mask_shape, dtype=torch.float32, device=device))
    # Add batch size dimension
    if add_batch_size:
        for index in range(len(masks)):
            masks[index] = masks[index].unsqueeze(dim=0)
    # Reverse order of masks to match the features of the vgg16 model
    masks.reverse()
    return masks


def normalize_0_1_batch(input: torch.tensor) -> torch.tensor:
    '''
    Normalize a given tensor to a range of [-1, 1]
    :param input: (Torch tensor) Input tensor
    :return: (Torch tensor) Normalized output tensor
    '''
    input_flatten = input.view(input.shape[0], -1)
    return ((input - torch.min(input_flatten, dim=1)[0][:, None, None, None]) / (
            torch.max(input_flatten, dim=1)[0][:, None, None, None] -
            torch.min(input_flatten, dim=1)[0][:, None, None, None]))

def normalize_m1_1_batch(input: torch.tensor) -> torch.tensor:
    '''
    Normalize a given tensor to a range of [-1, 1]
    :param input: (Torch tensor) Input tensor
    :return: (Torch tensor) Normalized output tensor
    '''
    input_flatten = input.view(input.shape[0], -1)
    return 2 * ((input - torch.min(input_flatten, dim=1)[0][:, None, None, None]) / (
            torch.max(input_flatten, dim=1)[0][:, None, None, None] -
            torch.min(input_flatten, dim=1)[0][:, None, None, None])) - 1


class Logger(object):
    """
    Class to log different metrics
    """

    def __init__(self) -> None:
        self.metrics = dict()
        self.hyperparameter = dict()

    def log(self, metric_name: str, value: float) -> None:
        """
        Method writes a given metric value into a dict including list for every metric
        :param metric_name: (str) Name of the metric
        :param value: (float) Value of the metric
        """
        if metric_name in self.metrics:
            self.metrics[metric_name].append(value)
        else:
            self.metrics[metric_name] = [value]

    def save_metrics(self, path: str) -> None:
        """
        Static method to save dict of metrics
        :param metrics: (Dict[str, List[float]]) Dict including metrics
        :param path: (str) Path to save metrics
        :param add_time_to_file_name: (bool) True if time has to be added to filename of every metric
        """
        # Save dict of hyperparameter as json file
        with open(os.path.join(path, 'hyperparameter.txt'), 'w') as json_file:
            json.dump(self.hyperparameter, json_file)
        # Iterate items in metrics dict
        for metric_name, values in self.metrics.items():
            # Convert list of values to torch tensor to use build in save method from torch
            values = torch.tensor(values)
            # Save values
            torch.save(values, os.path.join(path, '{}.pt'.format(metric_name)))
